# import pandas as pd
# import numpy as np
# import os
# import torch
# import torch.nn as nn
# import torch.optim as optim
# from torch.utils.data import Dataset, DataLoader
# from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, recall_score, confusion_matrix, roc_curve
# from sklearn.model_selection import StratifiedGroupKFold

# # ==========================================
# # 1. ì„¤ì • (ì—¬ê¸°ì„œ ìˆ«ìë¥¼ ë°”ê¾¸ì„¸ìš”!)
# # ==========================================
# BASE_DIR = r"D:\workspace\dataset\brain\BS_CONCH\aggregated_slides_v3"
# RESULT_FILE = r"D:\workspace\ts2bs_20251213\grand_final_10fold.xlsx"
# MODEL_DIR = r"D:\workspace\ts2bs_20251213\models\mil_10fold"

# EPOCHS = 30       # Foldê°€ ë§ì•„ì§€ë©´(ë°ì´í„° ì ì–´ì§) Epoch ë„ˆë¬´ ê¸¸ê²Œ ì¡ì§€ ë§ˆì„¸ìš”
# LR = 2e-4
# N_SPLITS = 15     # ğŸ‘ˆ ì—¬ê¸°ë¥¼ 10ìœ¼ë¡œ ë°”ê¾¸ë©´ ëª¨ë“  ê³³ì— ì ìš©ë©ë‹ˆë‹¤.
# DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

# EXPERIMENTS = [
#     ("TS Only", "agg_TS.csv"),
#     ("BS Only", "agg_BS.csv"),
#     ("Combined (Real)", "agg_Combined.csv"),
#     ("Gen BS Only", "agg_GEN_BS.csv"),
#     ("Combined2 (TS+Gen)", "agg_TS_GEN_BS.csv")
# ]

# # ... (Dataset, Model í´ë˜ìŠ¤ëŠ” ê¸°ì¡´ê³¼ ë™ì¼í•˜ë¯€ë¡œ ìƒëµ) ...
# class BagDataset(Dataset):
#     def __init__(self, df):
#         self.df = df
#     def __len__(self):
#         return len(self.df)
#     def __getitem__(self, idx):
#         row = self.df.iloc[idx]
#         try:
#             f = torch.load(row['file_path'], map_location='cpu')
#             if f.dim() == 1: f = f.unsqueeze(0)
#             return f, int(row['label'])
#         except:
#             return torch.zeros(1, 512), 0

# class GatedAttention(nn.Module):
#     def __init__(self):
#         super().__init__()
#         self.L=128; self.D=64; self.K=1
#         self.fe = nn.Sequential(nn.Linear(512, self.L), nn.ReLU())
#         self.av = nn.Sequential(nn.Linear(self.L, self.D), nn.Tanh())
#         self.au = nn.Sequential(nn.Linear(self.L, self.D), nn.Sigmoid())
#         self.w = nn.Linear(self.D, self.K)
#         self.clf = nn.Sequential(nn.Linear(self.L*self.K, 1), nn.Sigmoid())
#     def forward(self, x):
#         x = x.squeeze(0)
#         f = self.fe(x)
#         A = self.w(self.av(f) * self.au(f))
#         A = torch.transpose(A, 1, 0)
#         A = nn.functional.softmax(A, dim=1)
#         M = torch.mm(A, f)
#         return self.clf(M), A

# # ==========================================
# # 2. ë©”íŠ¸ë¦­ ê³„ì‚° (ì•ˆì „ì¥ì¹˜ ì¶”ê°€ë¨)
# # ==========================================
# def calculate_metrics(y_true, y_pred_prob):
#     # [ì•ˆì „ì¥ì¹˜] ë°ì´í„°ê°€ ì—†ê±°ë‚˜ í´ë˜ìŠ¤ê°€ í•˜ë‚˜ë¿ì´ë©´ ê³„ì‚° ë¶ˆê°€
#     if len(y_true) < 2 or len(np.unique(y_true)) < 2:
#         return {
#             "AUC": 0.5, "Accuracy": 0, "F1": 0, 
#             "Sensitivity": 0, "Specificity": 0, "Threshold": 0.5
#         }

#     # AUC
#     try: auc = roc_auc_score(y_true, y_pred_prob)
#     except: auc = 0.5

#     # Optimal Threshold (Youden Index)
#     try:
#         fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)
#         J = tpr - fpr
#         ix = np.argmax(J)
#         best_thresh = thresholds[ix]
#     except:
#         best_thresh = 0.5
    
#     if best_thresh < 0.1 or best_thresh > 0.9: best_thresh = 0.5

#     y_pred = [1 if p >= best_thresh else 0 for p in y_pred_prob]
    
#     acc = accuracy_score(y_true, y_pred)
#     f1 = f1_score(y_true, y_pred, zero_division=0)
#     sens = recall_score(y_true, y_pred, zero_division=0)
    
#     cm = confusion_matrix(y_true, y_pred)
#     tn, fp, fn, tp = cm.ravel() if cm.shape == (2, 2) else (0,0,0,0)
#     spec = tn / (tn + fp) if (tn + fp) > 0 else 0
    
#     return {
#         "AUC": auc, "Accuracy": acc, "F1": f1, 
#         "Sensitivity": sens, "Specificity": spec, "Threshold": best_thresh
#     }

# # ==========================================
# # 3. ê³µí†µ í™˜ì ì°¾ê¸° (N_SPLITS ì¸ì ì ìš©)
# # ==========================================
# def prepare_common_folds(experiments, n_splits, random_state=42):
#     print(f"ğŸ”’ [ë°ì´í„° ê²€ì¦] {n_splits}-Fold ë¶„í• ì„ ìœ„í•œ ê³µí†µ í™˜ì ì°¾ê¸°...")
#     patient_sets = []
#     dfs = {}
    
#     for name, fname in experiments:
#         path = os.path.join(BASE_DIR, fname)
#         if os.path.exists(path):
#             df = pd.read_csv(path)
#             patient_sets.append(set(df['patient_id'].unique()))
#             dfs[name] = df
            
#     common_patients = sorted(list(set.intersection(*patient_sets)))
#     print(f"âœ… ê³µí†µ í™˜ì ìˆ˜: {len(common_patients)}ëª…")

#     first_df = list(dfs.values())[0]
#     pid_to_label = first_df.groupby('patient_id')['label'].first().to_dict()
#     common_labels = [pid_to_label[pid] for pid in common_patients]

#     # ì—¬ê¸°ì„œ n_splits ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•¨!
#     sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=random_state)
#     patient_to_fold = {}
    
#     dummy_df = pd.DataFrame({'pid': common_patients, 'label': common_labels})
#     for fold, (train_idx, test_idx) in enumerate(sgkf.split(dummy_df, dummy_df['label'], dummy_df['pid'])):
#         test_pids = dummy_df.iloc[test_idx]['pid'].values
#         for pid in test_pids:
#             patient_to_fold[pid] = fold
            
#     return patient_to_fold

# # ==========================================
# # 4. ì‹¤í–‰ í•¨ìˆ˜ (ì•ˆì „ì¥ì¹˜ ì¶”ê°€ë¨)
# # ==========================================
# def run_experiment_no_val(exp_name, filename, patient_to_fold, n_splits):
#     print(f"\nğŸ§ª [{exp_name}] ì‹¤í—˜ ì‹œì‘ ({n_splits} Fold - No Val)")
#     csv_path = os.path.join(BASE_DIR, filename)
#     df = pd.read_csv(csv_path)
    
#     df = df[df['patient_id'].isin(patient_to_fold.keys())].reset_index(drop=True)
    
#     fold_metrics = []
    
#     # ì—¬ê¸°ì„œ n_splits ë³€ìˆ˜ë§Œí¼ ë”!
#     for fold in range(n_splits):
#         current_fold_mask = df['patient_id'].map(patient_to_fold) == fold
        
#         test_df = df[current_fold_mask]
#         train_df = df[~current_fold_mask] 
        
#         # [ì¤‘ìš”] ë¹ˆ ê¹¡í†µ Fold ë°©ì§€ (ì—ëŸ¬ ì›ì¸ ì°¨ë‹¨)
#         if len(test_df) == 0:
#             print(f"   âš ï¸ Fold {fold+1}: í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (Skip)")
#             continue

#         train_loader = DataLoader(BagDataset(train_df), batch_size=1, shuffle=True)
#         test_loader = DataLoader(BagDataset(test_df), batch_size=1, shuffle=False)
        
#         model = GatedAttention().to(DEVICE)
#         opt = optim.Adam(model.parameters(), LR)
#         crit = nn.BCELoss()
        
#         # Train
#         model.train()
#         for ep in range(EPOCHS):
#             for d, l in train_loader:
#                 d, l = d.to(DEVICE), l.to(DEVICE).float()
#                 opt.zero_grad()
#                 prob, _ = model(d)
#                 loss = crit(prob.view(-1), l.view(-1))
#                 loss.backward()
#                 opt.step()
                
#         # Test
#         model.eval()
#         probs, labels = [], []
#         with torch.no_grad():
#             for d, l in test_loader:
#                 d, l = d.to(DEVICE), l.to(DEVICE).float()
#                 probs.append(model(d)[0].item())
#                 labels.append(l.item())
        
#         # ê²°ê³¼ ê³„ì‚°
#         unique, counts = np.unique(labels, return_counts=True)
#         dist_str = str(dict(zip(unique, counts)))
        
#         met = calculate_metrics(labels, probs)
#         print(f"   ğŸ‘‰ Fold {fold+1}: AUC={met['AUC']:.4f} | Acc={met['Accuracy']:.4f} (Test: {len(labels)}ëª…, {dist_str})")
#         fold_metrics.append(met)
        
#     if not fold_metrics: return None

#     avg_metrics = {k: np.mean([m[k] for m in fold_metrics]) for k in fold_metrics[0].keys()}
#     avg_metrics['Experiment'] = exp_name
#     print(f"   âœ¨ í‰ê·  ê²°ê³¼: AUC={avg_metrics['AUC']:.4f}, Acc={avg_metrics['Accuracy']:.4f}")
#     return avg_metrics

# # ==========================================
# # 5. ë©”ì¸ ì‹¤í–‰
# # ==========================================
# if __name__ == "__main__":
#     # 1. ì—¬ê¸°ì„œ N_SPLITS(10)ì„ ë„˜ê²¨ì¤ë‹ˆë‹¤.
#     fold_map = prepare_common_folds(EXPERIMENTS, n_splits=N_SPLITS)
    
#     results = []
#     for name, fname in EXPERIMENTS:
#         # 2. ì—¬ê¸°ë„ N_SPLITS(10)ì„ ë„˜ê²¨ì¤ë‹ˆë‹¤.
#         res = run_experiment_no_val(name, fname, fold_map, n_splits=N_SPLITS)
#         if res: results.append(res)
        
#     if results:
#         df_res = pd.DataFrame(results)
#         df_res.to_excel(RESULT_FILE, index=False)
#         print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {RESULT_FILE}")

import pandas as pd
import numpy as np
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, recall_score, confusion_matrix, roc_curve
from sklearn.model_selection import StratifiedGroupKFold

# ==========================================
# 1. ì„¤ì • (15-Fold ì ìš©ë¨)
# ==========================================
BASE_DIR = r"D:\workspace\dataset\brain\BS_CONCH\aggregated_slides_v3"
RESULT_FILE = r"D:\workspace\ts2bs_20251213\grand_final_15fold.xlsx"
MODEL_DIR = r"D:\workspace\ts2bs_20251213\models\mil_15fold"

EPOCHS = 30       # ë°ì´í„°ê°€ ì ê³  Foldê°€ ë§ìœ¼ë¯€ë¡œ 30íšŒë©´ ì¶©ë¶„
LR = 2e-4
N_SPLITS = 5     # ğŸ‘ˆ 15-Fold ì„¤ì • (ì—¬ê¸°ë§Œ ë°”ê¾¸ë©´ ì „ì²´ ì ìš©)
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

EXPERIMENTS = [
    ("TS Only", "agg_TS.csv"),
    ("BS Only", "agg_BS.csv"),
    ("Combined (Real)", "agg_Combined.csv"),
    ("Gen BS Only", "agg_GEN_BS.csv"),
    ("Combined2 (TS+Gen)", "agg_TS_GEN_BS.csv")
]

# ==========================================
# 2. ë°ì´í„°ì…‹ ë° ëª¨ë¸ í´ë˜ìŠ¤
# ==========================================
class BagDataset(Dataset):
    def __init__(self, df):
        self.df = df
    def __len__(self):
        return len(self.df)
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        try:
            f = torch.load(row['file_path'], map_location='cpu')
            if f.dim() == 1: f = f.unsqueeze(0)
            return f, int(row['label'])
        except:
            return torch.zeros(1, 512), 0

class GatedAttention(nn.Module):
    def __init__(self):
        super().__init__()
        self.L=128; self.D=64; self.K=1
        self.fe = nn.Sequential(nn.Linear(512, self.L), nn.ReLU())
        self.av = nn.Sequential(nn.Linear(self.L, self.D), nn.Tanh())
        self.au = nn.Sequential(nn.Linear(self.L, self.D), nn.Sigmoid())
        self.w = nn.Linear(self.D, self.K)
        self.clf = nn.Sequential(nn.Linear(self.L*self.K, 1), nn.Sigmoid())
    def forward(self, x):
        x = x.squeeze(0)
        f = self.fe(x)
        A = self.w(self.av(f) * self.au(f))
        A = torch.transpose(A, 1, 0)
        A = nn.functional.softmax(A, dim=1)
        M = torch.mm(A, f)
        return self.clf(M), A

# ==========================================
# 3. ë©”íŠ¸ë¦­ ê³„ì‚° (ì•ˆì „ì¥ì¹˜ + Optimal Threshold)
# ==========================================
def calculate_metrics(y_true, y_pred_prob):
    # [ì•ˆì „ì¥ì¹˜] ë°ì´í„°ê°€ ì—†ê±°ë‚˜ í´ë˜ìŠ¤ê°€ í•˜ë‚˜ë¿ì´ë©´ 0.5 ë¦¬í„´
    if len(y_true) < 2 or len(np.unique(y_true)) < 2:
        return {
            "AUC": 0.5, "Accuracy": 0, "F1": 0, 
            "Sensitivity": 0, "Specificity": 0, "Threshold": 0.5
        }

    # AUC
    try: auc = roc_auc_score(y_true, y_pred_prob)
    except: auc = 0.5

    # Optimal Threshold (Youden Index)
    try:
        fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)
        J = tpr - fpr
        ix = np.argmax(J)
        best_thresh = thresholds[ix]
    except:
        best_thresh = 0.5
    
    # ë„ˆë¬´ ê·¹ë‹¨ì ì¸ Threshold ë³´ì •
    if best_thresh < 0.1 or best_thresh > 0.9: best_thresh = 0.5

    y_pred = [1 if p >= best_thresh else 0 for p in y_pred_prob]
    
    acc = accuracy_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred, zero_division=0)
    sens = recall_score(y_true, y_pred, zero_division=0)
    
    cm = confusion_matrix(y_true, y_pred)
    tn, fp, fn, tp = cm.ravel() if cm.shape == (2, 2) else (0,0,0,0)
    spec = tn / (tn + fp) if (tn + fp) > 0 else 0
    
    return {
        "AUC": auc, "Accuracy": acc, "F1": f1, 
        "Sensitivity": sens, "Specificity": spec, "Threshold": best_thresh
    }

# ==========================================
# 4. ê³µí†µ í™˜ì ì°¾ê¸° ë° Fold ì§€ì •
# ==========================================
def prepare_common_folds(experiments, n_splits, random_state=42):
    print(f"ğŸ”’ [ë°ì´í„° ê²€ì¦] {n_splits}-Fold ë¶„í• ì„ ìœ„í•œ ê³µí†µ í™˜ì ì°¾ê¸°...")
    patient_sets = []
    dfs = {}
    
    for name, fname in experiments:
        path = os.path.join(BASE_DIR, fname)
        if os.path.exists(path):
            df = pd.read_csv(path)
            patient_sets.append(set(df['patient_id'].unique()))
            dfs[name] = df
            
    common_patients = sorted(list(set.intersection(*patient_sets)))
    print(f"âœ… ê³µí†µ í™˜ì ìˆ˜: {len(common_patients)}ëª…")

    first_df = list(dfs.values())[0]
    pid_to_label = first_df.groupby('patient_id')['label'].first().to_dict()
    common_labels = [pid_to_label[pid] for pid in common_patients]

    # Stratified Group K-Fold (15ê°œë¡œ ë‚˜ëˆ”)
    sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=random_state)
    patient_to_fold = {}
    
    dummy_df = pd.DataFrame({'pid': common_patients, 'label': common_labels})
    for fold, (train_idx, test_idx) in enumerate(sgkf.split(dummy_df, dummy_df['label'], dummy_df['pid'])):
        test_pids = dummy_df.iloc[test_idx]['pid'].values
        for pid in test_pids:
            patient_to_fold[pid] = fold
            
    return patient_to_fold

# ==========================================
# 5. ì‹¤í—˜ ì‹¤í–‰ í•¨ìˆ˜ (No Validation, Train 100%)
# ==========================================
def run_experiment_no_val(exp_name, filename, patient_to_fold, n_splits):
    print(f"\nğŸ§ª [{exp_name}] ì‹¤í—˜ ì‹œì‘ ({n_splits} Fold - No Val)")
    csv_path = os.path.join(BASE_DIR, filename)
    df = pd.read_csv(csv_path)
    
    # ê³µí†µ í™˜ì í•„í„°ë§
    df = df[df['patient_id'].isin(patient_to_fold.keys())].reset_index(drop=True)
    
    fold_metrics = []
    
    # 0ë²ˆë¶€í„° 14ë²ˆ Foldê¹Œì§€ ìˆœíšŒ
    for fold in range(n_splits):
        current_fold_mask = df['patient_id'].map(patient_to_fold) == fold
        
        test_df = df[current_fold_mask]
        train_df = df[~current_fold_mask] # ë‚˜ë¨¸ì§€ ì „ë¶€ Train
        
        # [ì˜ˆì™¸ì²˜ë¦¬] í˜¹ì‹œ Test ë°ì´í„°ê°€ 0ê°œë©´ ìŠ¤í‚µ
        if len(test_df) == 0:
            print(f"   âš ï¸ Fold {fold+1}: í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (Skip)")
            continue

        train_loader = DataLoader(BagDataset(train_df), batch_size=1, shuffle=True)
        test_loader = DataLoader(BagDataset(test_df), batch_size=1, shuffle=False)
        
        model = GatedAttention().to(DEVICE)
        opt = optim.Adam(model.parameters(), LR)
        crit = nn.BCELoss()
        
        # Train Loop (Validation ì—†ìŒ)
        model.train()
        for ep in range(EPOCHS):
            for d, l in train_loader:
                d, l = d.to(DEVICE), l.to(DEVICE).float()
                opt.zero_grad()
                prob, _ = model(d)
                loss = crit(prob.view(-1), l.view(-1))
                loss.backward()
                opt.step()
                
        # Test Loop
        model.eval()
        probs, labels = [], []
        with torch.no_grad():
            for d, l in test_loader:
                d, l = d.to(DEVICE), l.to(DEVICE).float()
                probs.append(model(d)[0].item())
                labels.append(l.item())
        
        # ê²°ê³¼ ê³„ì‚°
        unique, counts = np.unique(labels, return_counts=True)
        dist_str = str(dict(zip(unique, counts)))
        
        met = calculate_metrics(labels, probs)
        print(f"   ğŸ‘‰ Fold {fold+1}: AUC={met['AUC']:.4f} | Acc={met['Accuracy']:.4f} (Test: {len(labels)}ëª…, {dist_str})")
        fold_metrics.append(met)
        
    if not fold_metrics: return None

    avg_metrics = {k: np.mean([m[k] for m in fold_metrics]) for k in fold_metrics[0].keys()}
    avg_metrics['Experiment'] = exp_name
    print(f"   âœ¨ í‰ê·  ê²°ê³¼: AUC={avg_metrics['AUC']:.4f}, Acc={avg_metrics['Accuracy']:.4f}, F1={avg_metrics['F1']:.4f}")
    return avg_metrics

# ==========================================
# 6. ë©”ì¸ ì‹¤í–‰
# ==========================================
if __name__ == "__main__":
    # 1. 15-Fold ì§€ë„ë¥¼ ë§Œë“­ë‹ˆë‹¤.
    fold_map = prepare_common_folds(EXPERIMENTS, n_splits=N_SPLITS)
    
    results = []
    for name, fname in EXPERIMENTS:
        # 2. 15-Fold ì‹¤í—˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        res = run_experiment_no_val(name, fname, fold_map, n_splits=N_SPLITS)
        if res: results.append(res)
        
    if results:
        df_res = pd.DataFrame(results)
        # ì»¬ëŸ¼ ìˆœì„œ ë³´ê¸° ì¢‹ê²Œ ì •ë ¬
        cols = ['Experiment', 'AUC', 'Accuracy', 'F1', 'Sensitivity', 'Specificity', 'Threshold']
        final_cols = [c for c in cols if c in df_res.columns]
        df_res = df_res[final_cols]
        
        df_res.to_excel(RESULT_FILE, index=False)
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {RESULT_FILE}")